{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjIdF9B4xLy4LGogcsw3dz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karan-p2112/Parkinsons-Disease-Detector/blob/main/parkinsons_disease_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8sCqJJGe0pE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parkinson's Disease Detection.ipynb\n",
        "\n",
        "Importing the Dependencies\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "JYTcDk17fRMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Data Collection & Analysis\"\"\"\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# printing the first 5 rows of the dataframe\n",
        "parkinsons_data.head()\n",
        "\n",
        "# number of rows and columns in the dataframe\n",
        "parkinsons_data.shape\n",
        "\n",
        "# getting more information about the dataset\n",
        "parkinsons_data.info()\n",
        "\n",
        "# checking for missing values in each column\n",
        "parkinsons_data.isnull().sum()\n",
        "\n",
        "# getting some statistical measures about the data\n",
        "parkinsons_data.describe()\n",
        "\n",
        "# distribution of target Variable\n",
        "parkinsons_data['status'].value_counts()\n",
        "\n",
        "\"\"\"1  --> Parkinson's Positive\n",
        "\n",
        "0 --> Healthy\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# grouping the data bas3ed on the target variable\n",
        "parkinsons_data.groupby('status').mean()\n",
        "\n",
        "\"\"\"Data Pre-Processing\n",
        "\n",
        "Separating the features & Target\n",
        "\"\"\"\n",
        "\n",
        "X = parkinsons_data.drop(columns=['name','status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "print(X)\n",
        "\n",
        "print(Y)\n",
        "\n",
        "\"\"\"Splitting the data to training data & Test data\"\"\"\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "print(X.shape, X_train.shape, X_test.shape)\n",
        "\n",
        "\"\"\"Data Standardization\"\"\"\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(X_train)\n",
        "\n",
        "\"\"\"Model Training\n",
        "\n",
        "Support Vector Machine Model\n",
        "\"\"\"\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "\n",
        "# training the SVM model with training data\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "\"\"\"Model Evaluation\n",
        "\n",
        "Accuracy Score\n",
        "\"\"\"\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "\n",
        "print('Accuracy score of training data : ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "\n",
        "print('Accuracy score of test data : ', test_data_accuracy)\n",
        "\n",
        "\"\"\"Building a Predictive System\"\"\"\n",
        "\n",
        "input_data = (197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "prediction = model.predict(std_data)\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print(\"The Person does not have Parkinsons Disease\")\n",
        "\n",
        "else:\n",
        "  print(\"The Person has Parkinsons\")"
      ],
      "metadata": {
        "id": "r1OnvPjlhvlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}